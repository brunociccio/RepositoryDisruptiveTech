# Importando os pacotes a serem utilizados
import pandas as pd
import numpy as np

# Importar o arquivo com os filmes e visualizar as primeiras linhas
filmes = pd.read_csv('https://criptodados.com.br/filmes/movies_metadata.csv', low_memory = False)
filmes.head(3)

# Importando o arquivo de avaliações e avaliando as primeiras linhas
avaliacoes = pd.read_csv('https://criptodados.com.br/filmes/ratings.csv')
avaliacoes.head()

# Filtrando somente as colunas necessários e renomeando nome das variaveis

# Seleciona somente as variaveis que iremos utilizar
filmes = filmes [['id','original_title','original_language','vote_count']]

# Renomeia as variaveis
filmes.rename(columns = {'id':'ID_FILME','original_title':'TITULO','original_language':'LINGUAGEM','vote_count':'QT_AVALIACOES'}, inplace = True)

# Exibe as primeiras linhas do arquivo tratado
filmes.head()

# Filtrando somente as colunas necessários e renomeando nome das variaveis

# Seleciona somente as variaveis que iremos utilizar
avaliacoes = avaliacoes [['userId','movieId','rating']]

# Renomeia as variaveis
avaliacoes.rename(columns = {'userId':'ID_USUARIO','movieId':'ID_FILME','rating':'AVALIACAO'}, inplace = True)

# Exibe as primeiras linhas do arquivo tratado
avaliacoes.head()

# Verificando se há valores nulos
filmes.isna().sum()

# Como são poucos os valores nulos iremos remover porque não terá impacto nenhum
filmes.dropna(inplace = True)

# Verificando se há valores nulos novamente em filmes

# Verificando se há valores nulos
avaliacoes.isna().sum()

# Verificando a quantidade de avaliacoes por usuarios
avaliacoes['ID_USUARIO'].value_counts()

# Vamos pegar o ID_USUARIO somente de usuários que fizeram mais de 999 avaliações
qt_avaliacoes = avaliacoes['ID_USUARIO'].value_counts() > 999
y = qt_avaliacoes[qt_avaliacoes].index
y.shape


# Visualizando os usuarios selecionados
y

# visualizando o tamanho do dataset Avaliações
avaliacoes.shape

# Pegando somente avaliacoes dos usuarios que avaliaram mais de 999 vezes
avaliacoes = avaliacoes[avaliacoes['ID_USUARIO'].isin(y)]

# visualizando o tamanho do dataset Avaliações
avaliacoes.shape

# Visualizando o DataFrame Filmes
filmes.head()

# Vamos usar os filmes que possuem somente uma quantidade de avaliações superior a 999 avaliações
filmes = filmes[filmes['QT_AVALIACOES'] > 999]

# Vamos agrupar e visualizar a quantidade de filmes pela linguagem
filmes_linguagem = filmes['LINGUAGEM'].value_counts()
filmes_linguagem.head(20)

# Selecionar somente os filmes da linguagem EN (English)
filmes = filmes[filmes['LINGUAGEM'] == 'en']

# Visualizar os tipos de dados das variaveis
filmes.info()

avaliacoes.info()

# Precisamos converter a variavel ID_FILME em inteiro
filmes['ID_FILME'] = filmes['ID_FILME'].astype(int)

# Concatenando os dataframes
avaliacoes_e_filmes = avaliacoes.merge(filmes, on = 'ID_FILME')
avaliacoes_e_filmes.head()

# Verificando a quantidade de filmes com avaliacoes pelo tamanho do arquivo
avaliacoes_e_filmes.shape

# Verificando se há valores nulos
avaliacoes_e_filmes.isna().sum()

# Vamos visualizar as primeiras 20 linhas do arquivo
avaliacoes_e_filmes.head(20)

# Agora precisamos fazer um PIVOT. O que queremos é que cada ID_USUARIO seja uma variavel com o respectivo valor de nota
# para cada filme avaliado
filmes_pivot = avaliacoes_e_filmes.pivot_table(columns = 'ID_USUARIO', index = 'TITULO', values = 'AVALIACAO')

# Avaliar o arquivo transformado para PIVOT
filmes_pivot.head(20)

# Os valores que são nulos iremos preencher com ZERO
filmes_pivot.fillna(0, inplace = True)
filmes_pivot.head()


# Vamos importar o csr_matrix do pacote SciPy
# Esse método possibilita criarmos uma matriz sparsa
from scipy.sparse import csr_matrix

# Vamos transformar o nosso dataset em uma matriz sparsa
filmes_sparse = csr_matrix(filmes_pivot)

# Tipo do objeto
type(filmes_sparse)

# Vamos importar o algoritmo KNN do SciKit Learn
from sklearn.neighbors import NearestNeighbors

# Criando e treinando o modelo preditivo
modelo = NearestNeighbors(algorithm = 'brute')
modelo.fit(filmes_sparse)

# 127 Hours
distances, sugestions = modelo.kneighbors(filmes_pivot.filter(items = ['127 Hours'], axis=0).values.reshape(1, -1))

for i in range(len(sugestions)):
  print(filmes_pivot.index[sugestions[i]])
